{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n"
     ]
    }
   ],
   "source": [
    "book_crossing = []\n",
    "generate_id = \"book_crossing_id_\"\n",
    "id_index = 0\n",
    "with open('datasets/BX-CSV-Dump/BX-Books.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=';')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        if index > 0:\n",
    "            \n",
    "            row.append(generate_id + str(id_index))\n",
    "            book_crossing.append(row)\n",
    "            id_index += 1\n",
    "        else:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bookID', 'title', 'authors', 'average_rating', 'isbn', 'isbn13', 'language_code', '  num_pages', 'ratings_count', 'text_reviews_count', 'publication_date', 'publisher']\n"
     ]
    }
   ],
   "source": [
    "book_goodread = []\n",
    "generate_id = \"goodread_id_\"\n",
    "id_index = 0\n",
    "with open('datasets/goodread.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        if index > 0:\n",
    "            row.append(generate_id + str(id_index))\n",
    "            book_goodread.append(row)\n",
    "            id_index += 1\n",
    "        else:\n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kate Brian\n",
      "Julian Peploe\n"
     ]
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "mydoc = minidom.parse('31FeaturesBooks.xml')\n",
    "\n",
    "items = mydoc.getElementsByTagName(\"book\")\n",
    "bestbook = []\n",
    "sum_ = 0\n",
    "for i in items:\n",
    "    try:\n",
    "        bestbook.append([i.attributes['id'].value, i.getElementsByTagName('isbn')[0].firstChild.data, \\\n",
    "                         i.getElementsByTagName('title')[0].firstChild.data, i.getElementsByTagName('authors'), \\\n",
    "                        i.getElementsByTagName('publisher')[0].firstChild.data, i.getElementsByTagName('pages')[0].firstChild.data,\n",
    "                        i.getElementsByTagName('published_date')[0].firstChild.data])\n",
    "    except:\n",
    "        bestbook.append([i.attributes['id'].value, '0', \\\n",
    "                         i.getElementsByTagName('title')[0].firstChild.data, i.getElementsByTagName('authors'), \\\n",
    "                        \"\", \"0\", \"0\"])\n",
    "\n",
    "\n",
    "# Example\n",
    "for i in bestbook[0][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_pairs_crossing_bestbook = []\n",
    "with open('crossing_bestbook.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        matching_pairs_crossing_bestbook.append(row)\n",
    "        \n",
    "matching_pairs_goodread_bestbook = []\n",
    "with open('goodread_bestbook.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        matching_pairs_goodread_bestbook.append(row)\n",
    "        \n",
    "matching_pairs_goodread_crossing = []\n",
    "with open('goodread_crossing.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        matching_pairs_goodread_crossing.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_index(list1, list2):\n",
    "\n",
    "    # Create an inverse index which keys are now sets\n",
    "    inverse_index = {}\n",
    "\n",
    "    for index, element in enumerate(list1):\n",
    "\n",
    "        if element not in inverse_index:\n",
    "            inverse_index[element] = {index}\n",
    "\n",
    "        else:\n",
    "            inverse_index[element].add(index)\n",
    "\n",
    "    # Traverse the second list    \n",
    "    matching_index = []\n",
    "\n",
    "    for index, element in enumerate(list2):\n",
    "\n",
    "        # We have to create one pair by element in the set of the inverse index\n",
    "        if element in inverse_index:\n",
    "            matching_index.extend([(x, index) for x in inverse_index[element]])\n",
    "\n",
    "    return matching_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Titles, but different ISBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossing + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Example:\n",
      "['0812542835', 'Reliquary', 'Douglas Preston', '1998', 'Tor Books', 'http://images.amazon.com/images/P/0812542835.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0812542835.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0812542835.01.LZZZZZZZ.jpg', 'book_crossing_id_11465']\n",
      "['bestbook_31_id_3', '0765354950', 'Reliquary', [<DOM Element: authors at 0x7fe9e0fff9c8>], 'Tor Books', '464', '1997-01-01']\n",
      "Douglas Preston\n",
      "Lincoln Child\n",
      "\n",
      "2. Example\n",
      "['037541570X', 'Omerta', 'Mario Puzo', '2000', 'Random House Audio', 'http://images.amazon.com/images/P/037541570X.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/037541570X.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/037541570X.01.LZZZZZZZ.jpg', 'book_crossing_id_239753']\n",
      "['bestbook_31_id_14', '0345432401', 'Omerta', [<DOM Element: authors at 0x7fe9e10233d8>], 'Ballantine Books', '369', '1999-01-01']\n",
      "Mario Puzo\n",
      "\n",
      "3. Example\n",
      "['0967774926', 'Sarah', 'K.M. Swan', '2002', 'K.M. Swan Books', 'http://images.amazon.com/images/P/0967774926.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0967774926.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0967774926.01.LZZZZZZZ.jpg', 'book_crossing_id_184152']\n",
      "['bestbook_31_id_127', '0765341174', 'Sarah', [<DOM Element: authors at 0x7fe9e116c768>], 'Forge', '341', '2000-01-01']\n",
      "Orson Scott Card\n"
     ]
    }
   ],
   "source": [
    "# Crossing + Bestbook\n",
    "crossing_bestbook_matching_title_diff = []\n",
    "\n",
    "# Title \n",
    "title_crossing = []\n",
    "for i in book_crossing:\n",
    "    title_crossing.append(i[1])\n",
    "    \n",
    "title_bestbook = []\n",
    "for i in bestbook:\n",
    "    title_bestbook.append(i[2])\n",
    "    \n",
    "# Find matching titles\n",
    "matching_titles_index = find_matching_index(title_crossing, title_bestbook)\n",
    "\n",
    "# Get subset books of matching titles\n",
    "subset_crossing = []\n",
    "subset_bestbook = []\n",
    "matching_ids = []\n",
    "for index in matching_titles_index:\n",
    "    subset_crossing.append(book_crossing[index[0]])\n",
    "    subset_bestbook.append(bestbook[index[1]])\n",
    "    matching_ids.append( [book_crossing[index[0]][-1],  bestbook[index[1]][0], index])\n",
    "    \n",
    "    \n",
    "# Get matches that are not in ISBN matching\n",
    "match_not_in_matching_crossing_bestbook = []\n",
    "for match in matching_ids:\n",
    "    if match[:2] not in [i[:2] for i in matching_pairs_crossing_bestbook]:\n",
    "        match_not_in_matching_crossing_bestbook.append(match)\n",
    "        \n",
    "# Final\n",
    "crossing_bestbook_matching_title_diff = [i[:2] for i in match_not_in_matching_crossing_bestbook]\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_crossing[match_not_in_matching_crossing_bestbook[0][2][0]])\n",
    "print(bestbook[match_not_in_matching_crossing_bestbook[0][2][1]])\n",
    "for i in bestbook[match_not_in_matching_crossing_bestbook[0][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "print(\"\\n2. Example\")\n",
    "print(book_crossing[match_not_in_matching_crossing_bestbook[10][2][0]])\n",
    "print(bestbook[match_not_in_matching_crossing_bestbook[10][2][1]])\n",
    "for i in bestbook[match_not_in_matching_crossing_bestbook[10][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_crossing[match_not_in_matching_crossing_bestbook[100][2][0]])\n",
    "print(bestbook[match_not_in_matching_crossing_bestbook[100][2][1]])\n",
    "for i in bestbook[match_not_in_matching_crossing_bestbook[100][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodread + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Example:\n",
      "['25200', 'Silence', 'Shūsaku Endō/William Johnston', '4.08', '0800871863', '9780800871864', 'eng', '201', '17485', '2100', '1/1/1999', 'Taplinger Publishing', 'goodread_id_6723']\n",
      "['bestbook_31_id_19', '0', 'Silence', [<DOM Element: authors at 0x7fe9e102ff20>], '', '0', '0']\n",
      "Natasha Preston\n",
      "\n",
      "2. Example\n",
      "['16609', 'Leviathan', 'Thomas Hobbes/Edwin M. Curley', '3.70', '0872201775', '9780872201774', 'eng', '672', '500', '32', '3/1/1994', 'Hackett Publishing Company  Inc.', 'goodread_id_4619']\n",
      "['bestbook_31_id_287', '0140178139', 'Leviathan', [<DOM Element: authors at 0x7fe9e1347768>], 'Penguin Books', '275', '1992-01-01']\n",
      "Paul Auster\n",
      "\n",
      "3. Example\n",
      "['43926', 'The Innocent', 'Harlan Coben', '3.96', '045121577X', '9780451215772', 'eng', '503', '21382', '1229', '4/25/2006', 'Dutton', 'goodread_id_10765']\n",
      "['bestbook_31_id_4239', '0', 'The Innocent', [<DOM Element: authors at 0x7fe9e3f15898>], '', '0', '0']\n",
      "Ian McEwan\n"
     ]
    }
   ],
   "source": [
    "# Goodread + Bestbook\n",
    "goodread_bestbook_matching_title_diff = []\n",
    "\n",
    "# Title \n",
    "title_goodread = []\n",
    "for i in book_goodread:\n",
    "    title_goodread.append(i[1])\n",
    "    \n",
    "title_bestbook = []\n",
    "for i in bestbook:\n",
    "    title_bestbook.append(i[2])\n",
    "    \n",
    "# Find matching titles\n",
    "matching_titles_index = find_matching_index(title_goodread, title_bestbook)\n",
    "\n",
    "# Get subset books of matching titles\n",
    "subset_goodread = []\n",
    "subset_bestbook = []\n",
    "matching_ids = []\n",
    "for index in matching_titles_index:\n",
    "    subset_goodread.append(book_goodread[index[0]])\n",
    "    subset_bestbook.append(bestbook[index[1]])\n",
    "    matching_ids.append( [book_goodread[index[0]][-1],  bestbook[index[1]][0], index])\n",
    "    \n",
    "    \n",
    "# Get matches that are not in ISBN matching\n",
    "match_not_in_matching_goodread_bestbook = []\n",
    "for match in matching_ids:\n",
    "    if match[:2] not in [i[:2] for i in matching_pairs_goodread_bestbook]:\n",
    "        match_not_in_matching_goodread_bestbook.append(match)\n",
    "        \n",
    "# Final\n",
    "goodread_bestbook_matching_title_diff = [i[:2] for i in match_not_in_matching_goodread_bestbook]\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[match_not_in_matching_goodread_bestbook[0][2][0]])\n",
    "print(bestbook[match_not_in_matching_goodread_bestbook[0][2][1]])\n",
    "for i in bestbook[match_not_in_matching_goodread_bestbook[0][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[match_not_in_matching_goodread_bestbook[10][2][0]])\n",
    "print(bestbook[match_not_in_matching_goodread_bestbook[10][2][1]])\n",
    "for i in bestbook[match_not_in_matching_goodread_bestbook[10][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[match_not_in_matching_goodread_bestbook[100][2][0]])\n",
    "print(bestbook[match_not_in_matching_goodread_bestbook[100][2][1]])\n",
    "for i in bestbook[match_not_in_matching_goodread_bestbook[100][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodread + Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Example:\n",
      "['12557', \"The Kitchen God's Wife\", 'Amy Tan', '4.01', '0143038109', '9780143038108', 'en-US', '416', '66503', '1661', '9/21/2006', 'Penguin Books', 'goodread_id_3442']\n",
      "['0399135782', \"The Kitchen God's Wife\", 'Amy Tan', '1991', 'Putnam Pub Group', 'http://images.amazon.com/images/P/0399135782.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0399135782.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0399135782.01.LZZZZZZZ.jpg', 'book_crossing_id_5']\n",
      "\n",
      "2. Example\n",
      "['21365', 'From the Corner of His Eye', 'Dean Koontz/Stephen Lang', '4.03', '0553502697', '9780553502695', 'en-US', '0', '29', '3', '12/26/2000', 'Random House Audio Publishing Group', 'goodread_id_5732']\n",
      "['0553582747', 'From the Corner of His Eye', 'Dean Koontz', '2001', 'Bantam Books', 'http://images.amazon.com/images/P/0553582747.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0553582747.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0553582747.01.LZZZZZZZ.jpg', 'book_crossing_id_46']\n",
      "\n",
      "3. Example\n",
      "['11507', 'My Name Is Asher Lev', 'Chaim Potok', '4.21', '1400031044', '9781400031047', 'eng', '369', '32785', '2398', '3/11/2003', 'Anchor', 'goodread_id_3130']\n",
      "['0449911683', 'My Name Is Asher Lev', 'Chaim Potok', '1996', 'Ballantine Books', 'http://images.amazon.com/images/P/0449911683.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0449911683.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0449911683.01.LZZZZZZZ.jpg', 'book_crossing_id_718']\n"
     ]
    }
   ],
   "source": [
    "# Goodread + Crossing\n",
    "goodread_crossing_matching_title_diff = []\n",
    "\n",
    "# Title \n",
    "title_goodread = []\n",
    "for i in book_goodread:\n",
    "    title_goodread.append(i[1])\n",
    "    \n",
    "title_crossing = []\n",
    "for i in book_crossing:\n",
    "    title_crossing.append(i[1])\n",
    "    \n",
    "# Find matching titles\n",
    "matching_titles_index = find_matching_index(title_goodread, title_crossing)\n",
    "\n",
    "# Get subset books of matching titles\n",
    "subset_goodread = []\n",
    "subset_crossing = []\n",
    "matching_ids = []\n",
    "for index in matching_titles_index:\n",
    "    subset_goodread.append(book_goodread[index[0]])\n",
    "    subset_crossing.append(book_crossing[index[1]])\n",
    "    matching_ids.append( [book_goodread[index[0]][-1],  book_crossing[index[1]][-1], index])\n",
    "    \n",
    "    \n",
    "# Get matches that are not in ISBN matching\n",
    "match_not_in_matching_goodread_crossing = []\n",
    "for match in matching_ids:\n",
    "    if match[:2] not in [i[:2] for i in matching_pairs_goodread_crossing]:\n",
    "        match_not_in_matching_goodread_crossing.append(match)\n",
    "        \n",
    "# Final\n",
    "goodread_crossing_matching_title_diff = [i[:2] for i in match_not_in_matching_goodread_crossing]\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[match_not_in_matching_goodread_crossing[0][2][0]])\n",
    "print(book_crossing[match_not_in_matching_goodread_crossing[0][2][1]])\n",
    "\n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[match_not_in_matching_goodread_crossing[10][2][0]])\n",
    "print(book_crossing[match_not_in_matching_goodread_crossing[10][2][1]])\n",
    "\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[match_not_in_matching_goodread_crossing[100][2][0]])\n",
    "print(book_crossing[match_not_in_matching_goodread_crossing[100][2][1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Titles, different authors, but different ISBN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossing + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 13605\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['0373029306', 'Black Sheep', 'Susan Fox', '1988', 'Harlequin', 'http://images.amazon.com/images/P/0373029306.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0373029306.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0373029306.01.LZZZZZZZ.jpg', 'book_crossing_id_72704']\n",
      "['bestbook_31_id_5', '0099468034', 'Black Sheep', [<DOM Element: authors at 0x7fe9e1006508>], 'Arrow', '252', '1966-03-01']\n",
      "Georgette Heyer\n",
      "\n",
      "2. Example\n",
      "['0786014210', 'Darkness', 'Sam Siciliano', '2001', 'Kensington Publishing Corporation', 'http://images.amazon.com/images/P/0786014210.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0786014210.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0786014210.01.LZZZZZZZ.jpg', 'book_crossing_id_1750']\n",
      "['bestbook_31_id_22', '0', 'Darkness', [<DOM Element: authors at 0x7fe9e103b0e0>], '', '0', '0']\n",
      "Laurann Dohner\n",
      "\n",
      "3. Example\n",
      "['1576737659', 'It Had to Be You', 'Linda Windsor', '2001', 'Multnomah', 'http://images.amazon.com/images/P/1576737659.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/1576737659.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/1576737659.01.LZZZZZZZ.jpg', 'book_crossing_id_217994']\n",
      "['bestbook_31_id_372', '0316017680', 'It Had to Be You', [<DOM Element: authors at 0x7fe9e143baf8>], 'Megan Tingley', '416', '2007-01-01']\n",
      "Cecily von Ziegesar\n"
     ]
    }
   ],
   "source": [
    "crossing_bestbook_matching_title_diff_authors_diff = []\n",
    "\n",
    "for match in match_not_in_matching_crossing_bestbook:\n",
    "    for name in [i.getElementsByTagName(\"name\")[0].firstChild.data for i in bestbook[match[2][1]][3][0].getElementsByTagName(\"author\")]:\n",
    "        if levenshtein_distance(name.replace(\"  \", \" \").lower(), book_crossing[match[2][0]][2].replace(\"  \", \" \").lower()) < 3:\n",
    "            same = True\n",
    "    if not same:\n",
    "        crossing_bestbook_matching_title_diff_authors_diff.append(match)\n",
    "    same = False  \n",
    "\n",
    "print(\"\\nTotal: {}\\n\\n\".format(len(crossing_bestbook_matching_title_diff_authors_diff)))\n",
    "\n",
    " \n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_crossing[crossing_bestbook_matching_title_diff_authors_diff[0][2][0]])\n",
    "print(bestbook[crossing_bestbook_matching_title_diff_authors_diff[0][2][1]])\n",
    "for i in bestbook[crossing_bestbook_matching_title_diff_authors_diff[0][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n2. Example\")\n",
    "print(book_crossing[crossing_bestbook_matching_title_diff_authors_diff[9][2][0]])\n",
    "print(bestbook[crossing_bestbook_matching_title_diff_authors_diff[9][2][1]])\n",
    "for i in bestbook[crossing_bestbook_matching_title_diff_authors_diff[9][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_crossing[crossing_bestbook_matching_title_diff_authors_diff[100][2][0]])\n",
    "print(bestbook[crossing_bestbook_matching_title_diff_authors_diff[100][2][1]])\n",
    "for i in bestbook[crossing_bestbook_matching_title_diff_authors_diff[100][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodread + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 729\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['25200', 'Silence', 'Shūsaku Endō/William Johnston', '4.08', '0800871863', '9780800871864', 'eng', '201', '17485', '2100', '1/1/1999', 'Taplinger Publishing', 'goodread_id_6723']\n",
      "['bestbook_31_id_19', '0', 'Silence', [<DOM Element: authors at 0x7fe9e102ff20>], '', '0', '0']\n",
      "Natasha Preston\n",
      "\n",
      "2. Example\n",
      "['22912', 'Collected Stories', 'Franz Kafka/Willa Muir/Edwin Muir/Gabriel Josipovici', '4.35', '0679423036', '9780679423034', 'eng', '566', '445', '30', '10/26/1993', 'Knopf', 'goodread_id_6106']\n",
      "['bestbook_31_id_394', '0', 'Collected Stories', [<DOM Element: authors at 0x7fe9e1482af8>], '', '0', '0']\n",
      "William Faulkner\n",
      "\n",
      "3. Example\n",
      "['18789', 'Sanctuary', 'William Faulkner', '3.64', '0679748148', '9780679748144', 'eng', '317', '9336', '544', '12/6/1993', 'Vintage', 'goodread_id_5184']\n",
      "['bestbook_31_id_6126', '0756403413', 'Sanctuary', [<DOM Element: authors at 0x7fe9e54e7e88>], 'DAW', '448', '2005-01-01']\n",
      "Mercedes Lackey\n"
     ]
    }
   ],
   "source": [
    "goodread_bestbook_matching_title_diff_authors_diff = []\n",
    "same = False\n",
    "for match in match_not_in_matching_goodread_bestbook:\n",
    "    for name in [i.getElementsByTagName(\"name\")[0].firstChild.data for i in bestbook[match[2][1]][3][0].getElementsByTagName(\"author\")]:\n",
    "        for name_2 in book_goodread[match[2][0]][2].split(\"/\"):\n",
    "            if levenshtein_distance(name.replace(\"  \", \" \").lower(), name_2.replace(\"  \", \" \").lower()) < 2:\n",
    "                same = True\n",
    "    if not same:\n",
    "        goodread_bestbook_matching_title_diff_authors_diff.append(match)\n",
    "    same = False       \n",
    "    \n",
    "print(\"\\nTotal: {}\\n\\n\".format(len(goodread_bestbook_matching_title_diff_authors_diff)))\n",
    "\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[goodread_bestbook_matching_title_diff_authors_diff[0][2][0]])\n",
    "print(bestbook[goodread_bestbook_matching_title_diff_authors_diff[0][2][1]])\n",
    "for i in bestbook[goodread_bestbook_matching_title_diff_authors_diff[0][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[goodread_bestbook_matching_title_diff_authors_diff[10][2][0]])\n",
    "print(bestbook[goodread_bestbook_matching_title_diff_authors_diff[10][2][1]])\n",
    "for i in bestbook[goodread_bestbook_matching_title_diff_authors_diff[10][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[goodread_bestbook_matching_title_diff_authors_diff[100][2][0]])\n",
    "print(bestbook[goodread_bestbook_matching_title_diff_authors_diff[100][2][1]])\n",
    "for i in bestbook[goodread_bestbook_matching_title_diff_authors_diff[100][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodread + Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 2054\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['28086', 'One Hundred Years of Solitude', 'Gabriel García Márquez/Gregory Rabassa', '4.07', '0140157514', '9780140157512', 'eng', '422', '640', '65', '6/11/1972', 'Penguin Books Ltd', 'goodread_id_7299']\n",
      "['0060929790', 'One Hundred Years of Solitude', 'Gabriel Garcia Marquez', '1998', 'Perennial', 'http://images.amazon.com/images/P/0060929790.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0060929790.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0060929790.01.LZZZZZZZ.jpg', 'book_crossing_id_133']\n",
      "\n",
      "2. Example\n",
      "['40004', 'Hannibal', 'Theodore Ayrault Dodge/Ian M. Cuthbertson', '4.13', '076076896X', '9780760768969', 'eng', '592', '19', '2', '7/16/2005', 'Barnes  Noble', 'goodread_id_9929']\n",
      "['038529929X', 'Hannibal', 'Thomas Harris', '1999', 'Del Sol Press', 'http://images.amazon.com/images/P/038529929X.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/038529929X.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/038529929X.01.LZZZZZZZ.jpg', 'book_crossing_id_877']\n",
      "\n",
      "3. Example\n",
      "['15735', 'Breakfast of Champions', 'Robert Egan/Kurt Vonnegut Jr.', '4.00', '0573605734', '9780573605734', 'eng', '106', '17', '0', '4/7/2017', 'Samuel French  Inc.', 'goodread_id_4381']\n",
      "['0385334206', 'Breakfast of Champions', 'Kurt Vonnegut', '1999', 'Delta', 'http://images.amazon.com/images/P/0385334206.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0385334206.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0385334206.01.LZZZZZZZ.jpg', 'book_crossing_id_7286']\n"
     ]
    }
   ],
   "source": [
    "goodread_crossing_matching_title_diff_authors_diff = []\n",
    "same = False\n",
    "for match in match_not_in_matching_goodread_crossing:\n",
    "    for name in book_goodread[match[2][0]][2].split(\"/\"):\n",
    "        if levenshtein_distance(name.replace(\"  \", \" \").lower(), book_crossing[match[2][1]][2].replace(\"  \", \"\").lower()) < 2:\n",
    "            same = True\n",
    "    if not same:\n",
    "        goodread_crossing_matching_title_diff_authors_diff.append(match)\n",
    "    same = False  \n",
    "\n",
    "print(\"\\nTotal: {}\\n\\n\".format(len(goodread_crossing_matching_title_diff_authors_diff)))\n",
    "\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[goodread_crossing_matching_title_diff_authors_diff[1][2][0]])\n",
    "print(book_crossing[goodread_crossing_matching_title_diff_authors_diff[1][2][1]])\n",
    "\n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[goodread_crossing_matching_title_diff_authors_diff[10][2][0]])\n",
    "print(book_crossing[goodread_crossing_matching_title_diff_authors_diff[10][2][1]])\n",
    "\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[goodread_crossing_matching_title_diff_authors_diff[102][2][0]])\n",
    "print(book_crossing[goodread_crossing_matching_title_diff_authors_diff[102][2][1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Titles, matching authors, but different ISBN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossing + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 10399\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['0812542835', 'Reliquary', 'Douglas Preston', '1998', 'Tor Books', 'http://images.amazon.com/images/P/0812542835.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0812542835.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0812542835.01.LZZZZZZZ.jpg', 'book_crossing_id_11465']\n",
      "['bestbook_31_id_3', '0765354950', 'Reliquary', [<DOM Element: authors at 0x7fe9e0fff9c8>], 'Tor Books', '464', '1997-01-01']\n",
      "Douglas Preston\n",
      "Lincoln Child\n",
      "\n",
      "2. Example\n",
      "['0808519085', 'Cycle of the Werewolf', 'Stephen King', '1999', 'Sagebrush Bound', 'http://images.amazon.com/images/P/0808519085.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0808519085.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0808519085.01.LZZZZZZZ.jpg', 'book_crossing_id_170703']\n",
      "['bestbook_31_id_21', '0451822196', 'Cycle of the Werewolf', [<DOM Element: authors at 0x7fe9e1039508>], 'Signet Books', '128', '1983-11-01']\n",
      "Stephen King\n",
      "Bernie Wrightson\n",
      "\n",
      "3. Example\n",
      "['084394952X', 'Dark Legend', 'Christine Feehan', '2002', 'Leisure Books', 'http://images.amazon.com/images/P/084394952X.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/084394952X.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/084394952X.01.LZZZZZZZ.jpg', 'book_crossing_id_33870']\n",
      "['bestbook_31_id_246', '0843949520', 'Dark Legend', [<DOM Element: authors at 0x7fe9e12c9898>], 'Leisure Books', '382', '2002-01-28']\n",
      "Christine Feehan\n"
     ]
    }
   ],
   "source": [
    "crossing_bestbook_matching_title_matching_authors_diff = []\n",
    "same = False\n",
    "for match in match_not_in_matching_crossing_bestbook:\n",
    "    for name in [i.getElementsByTagName(\"name\")[0].firstChild.data for i in bestbook[match[2][1]][3][0].getElementsByTagName(\"author\")]:\n",
    "        if levenshtein_distance(name.replace(\"  \", \" \").lower(), book_crossing[match[2][0]][2].replace(\"  \", \" \").lower()) < 3:\n",
    "            same = True\n",
    "    if same:\n",
    "        crossing_bestbook_matching_title_matching_authors_diff.append(match)\n",
    "    same = False  \n",
    "\n",
    "print(\"\\nTotal: {}\\n\\n\".format(len(crossing_bestbook_matching_title_matching_authors_diff)))\n",
    "\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_crossing[crossing_bestbook_matching_title_matching_authors_diff[0][2][0]])\n",
    "print(bestbook[crossing_bestbook_matching_title_matching_authors_diff[0][2][1]])\n",
    "for i in bestbook[crossing_bestbook_matching_title_matching_authors_diff[0][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n2. Example\")\n",
    "print(book_crossing[crossing_bestbook_matching_title_matching_authors_diff[9][2][0]])\n",
    "print(bestbook[crossing_bestbook_matching_title_matching_authors_diff[9][2][1]])\n",
    "for i in bestbook[crossing_bestbook_matching_title_matching_authors_diff[9][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_crossing[crossing_bestbook_matching_title_matching_authors_diff[100][2][0]])\n",
    "print(bestbook[crossing_bestbook_matching_title_matching_authors_diff[100][2][1]])\n",
    "for i in bestbook[crossing_bestbook_matching_title_matching_authors_diff[100][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodread + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 1174\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['14131', 'Mao II', 'Don DeLillo/Marianne Véron', '3.68', '2742735402', '9782742735402', 'fre', '278', '10', '1', '10/27/2001', 'Babel', 'goodread_id_3980']\n",
      "['bestbook_31_id_89', '0140152741', 'Mao II', [<DOM Element: authors at 0x7fe9e10f8210>], 'Penguin Books', '254', '1991-01-01']\n",
      "Don DeLillo\n",
      "\n",
      "2. Example\n",
      "['1937', 'Little Women', 'Louisa May Alcott/Jessie Willcox Smith/Frank T. Merrill', '4.07', '0517221160', '9780517221167', 'eng', '389', '166', '9', '9/3/2002', 'Gramercy Books', 'goodread_id_594']\n",
      "['bestbook_31_id_573', '0', 'Little Women', [<DOM Element: authors at 0x7fe9e16599c8>], '', '0', '0']\n",
      "Louisa May Alcott\n",
      "\n",
      "3. Example\n",
      "['28193', 'When Santa Fell to Earth', 'Cornelia Funke/Paul   Howard/Oliver G. Latsch', '3.76', '043978204X', '9780439782043', 'eng', '167', '1840', '245', '10/1/2006', 'Chicken House / Scholastic', 'goodread_id_7314']\n",
      "['bestbook_31_id_10413', '0439782040', 'When Santa Fell to Earth', [<DOM Element: authors at 0x7fe9e807fdf0>], 'Chicken House / Scholastic', '167', '1994-01-01']\n",
      "Cornelia Funke\n",
      "Paul Howard\n",
      "Oliver G. Latsch\n"
     ]
    }
   ],
   "source": [
    "goodread_bestbook_matching_title_matching_authors_diff = []\n",
    "same = False\n",
    "for match in match_not_in_matching_goodread_bestbook:\n",
    "    for name in [i.getElementsByTagName(\"name\")[0].firstChild.data for i in bestbook[match[2][1]][3][0].getElementsByTagName(\"author\")]:\n",
    "        for name_2 in book_goodread[match[2][0]][2].split(\"/\"):\n",
    "            if levenshtein_distance(name.replace(\"  \", \" \").lower(), name_2.replace(\"  \", \" \").lower()) < 2:\n",
    "                same = True\n",
    "    if same:\n",
    "        goodread_bestbook_matching_title_matching_authors_diff.append(match)\n",
    "    same = False       \n",
    "    \n",
    "print(\"\\nTotal: {}\\n\\n\".format(len(goodread_bestbook_matching_title_matching_authors_diff)))\n",
    "\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[goodread_bestbook_matching_title_matching_authors_diff[0][2][0]])\n",
    "print(bestbook[goodread_bestbook_matching_title_matching_authors_diff[0][2][1]])\n",
    "for i in bestbook[goodread_bestbook_matching_title_matching_authors_diff[0][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[goodread_bestbook_matching_title_matching_authors_diff[10][2][0]])\n",
    "print(bestbook[goodread_bestbook_matching_title_matching_authors_diff[10][2][1]])\n",
    "for i in bestbook[goodread_bestbook_matching_title_matching_authors_diff[10][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[goodread_bestbook_matching_title_matching_authors_diff[100][2][0]])\n",
    "print(bestbook[goodread_bestbook_matching_title_matching_authors_diff[100][2][1]])\n",
    "for i in bestbook[goodread_bestbook_matching_title_matching_authors_diff[100][2][1]][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodread + Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 5895\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['2661', 'To Kill a Mockingbird', 'Harper Lee', '4.27', '0061205699', '9780061205699', 'en-US', '323', '271', '34', '10/17/2006', 'Harper', 'goodread_id_800']\n",
      "['0446310786', 'To Kill a Mockingbird', 'Harper Lee', '1988', 'Little Brown &amp; Company', 'http://images.amazon.com/images/P/0446310786.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0446310786.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0446310786.01.LZZZZZZZ.jpg', 'book_crossing_id_37']\n",
      "\n",
      "2. Example\n",
      "['5351', 'The Street Lawyer', 'John Grisham', '3.83', '0385339097', '9780385339094', 'eng', '384', '89947', '1813', '4/26/2005', 'Bantam', 'goodread_id_1550']\n",
      "['0440225701', 'The Street Lawyer', 'JOHN GRISHAM', '1999', 'Dell', 'http://images.amazon.com/images/P/0440225701.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0440225701.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0440225701.01.LZZZZZZZ.jpg', 'book_crossing_id_52']\n",
      "\n",
      "3. Example\n",
      "['3469', 'Nights in Rodanthe', 'Nicholas Sparks', '3.84', '0446691798', '9780446691796', 'en-US', '212', '1596', '157', '8/1/2004', 'Warner Books', 'goodread_id_1023']\n",
      "['0446531332', 'Nights in Rodanthe', 'Nicholas Sparks', '2002', 'Warner Books', 'http://images.amazon.com/images/P/0446531332.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0446531332.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0446531332.01.LZZZZZZZ.jpg', 'book_crossing_id_776']\n"
     ]
    }
   ],
   "source": [
    "goodread_crossing_matching_title_matching_authors_diff = []\n",
    "same = False\n",
    "for match in match_not_in_matching_goodread_crossing:\n",
    "    for name in book_goodread[match[2][0]][2].split(\"/\"):\n",
    "        if levenshtein_distance(name.replace(\"  \", \" \").lower(), book_crossing[match[2][1]][2].replace(\"  \", \"\").lower()) < 2:\n",
    "            same = True\n",
    "    if same:\n",
    "        goodread_crossing_matching_title_matching_authors_diff.append(match)\n",
    "    same = False  \n",
    "\n",
    "    \n",
    "print(\"\\nTotal: {}\\n\\n\".format(len(goodread_crossing_matching_title_matching_authors_diff)))\n",
    "\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[goodread_crossing_matching_title_matching_authors_diff[1][2][0]])\n",
    "print(book_crossing[goodread_crossing_matching_title_matching_authors_diff[1][2][1]])\n",
    "\n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[goodread_crossing_matching_title_matching_authors_diff[10][2][0]])\n",
    "print(book_crossing[goodread_crossing_matching_title_matching_authors_diff[10][2][1]])\n",
    "\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[goodread_crossing_matching_title_matching_authors_diff[102][2][0]])\n",
    "print(book_crossing[goodread_crossing_matching_title_matching_authors_diff[102][2][1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Title, different authors, but matching ISBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossing + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 352 of 7440\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['1562827049', 'The Diary of Jack the Ripper/the Discovery, the Investigation, the Debate', 'Jack', '1993', 'Hyperion Books', 'http://images.amazon.com/images/P/1562827049.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/1562827049.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/1562827049.01.LZZZZZZZ.jpg', 'book_crossing_id_616']\n",
      "['bestbook_31_id_35844', '1562827049', 'The Diary of Jack the Ripper: The Discovery, the Investigation, the Authentication, the Debate', [<DOM Element: authors at 0x7fe9d8a8c210>], 'Hyperion', '352', '1993-01-01']\n",
      "Shirley Harrison\n",
      "\n",
      "2. Example\n",
      "['0553212419', 'Sherlock Holmes : The Complete Novels and Stories (Bantam Classic) Volume I', 'Arthur Conan, Sir Doyle', '1986', 'Bantam', 'http://images.amazon.com/images/P/0553212419.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0553212419.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0553212419.01.LZZZZZZZ.jpg', 'book_crossing_id_7424']\n",
      "['bestbook_31_id_44145', '0553212419', 'Sherlock Holmes: The Complete Novels and Stories, Volume I', [<DOM Element: authors at 0x7fe9be437f20>], 'Bantam Classics', '1059', '1927-01-01']\n",
      "Arthur Conan Doyle\n",
      "\n",
      "3. Example\n",
      "['0786832347', \"Disney's Storybook Collection (Disney Storybook Collections)\", 'Various', '1998', 'Disney Press', 'http://images.amazon.com/images/P/0786832347.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0786832347.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0786832347.01.LZZZZZZZ.jpg', 'book_crossing_id_51827']\n",
      "['bestbook_31_id_39486', '0786832347', \"Disney's Storybook Collection\", [<DOM Element: authors at 0x7fe9baf0d9c8>], 'Disney Press', '320', '1998-01-01']\n",
      "Nancy Parent\n",
      "Walt Disney Company\n"
     ]
    }
   ],
   "source": [
    "crossing_bestbook_diff_title_match_isbn= []\n",
    "same = False\n",
    "for match in matching_pairs_crossing_bestbook:\n",
    "    first_index = int(match[0].split(\"_\")[-1])\n",
    "    second_index = int(match[1].split(\"_\")[-1])\n",
    "\n",
    "    if book_crossing[first_index][1] != bestbook[second_index][2]:\n",
    "        for name in [i.getElementsByTagName(\"name\")[0].firstChild.data for i in bestbook[second_index][3][0].getElementsByTagName(\"author\")]:\n",
    "            if levenshtein_distance(name.replace(\"  \", \" \").lower(), book_crossing[first_index][2].replace(\"  \", \" \").lower()) < 3:\n",
    "                same = True\n",
    "        if not same:\n",
    "            crossing_bestbook_diff_title_match_isbn.append(match)\n",
    "        same = False \n",
    "    \n",
    "print(\"\\nTotal: {} of {}\\n\\n\".format(len(crossing_bestbook_diff_title_match_isbn), len(matching_pairs_crossing_bestbook)))\n",
    "\n",
    "\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_crossing[int(crossing_bestbook_diff_title_match_isbn[0][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(crossing_bestbook_diff_title_match_isbn[0][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(crossing_bestbook_diff_title_match_isbn[0][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n2. Example\")\n",
    "print(book_crossing[int(crossing_bestbook_diff_title_match_isbn[10][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(crossing_bestbook_diff_title_match_isbn[10][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(crossing_bestbook_diff_title_match_isbn[10][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_crossing[int(crossing_bestbook_diff_title_match_isbn[100][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(crossing_bestbook_diff_title_match_isbn[100][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(crossing_bestbook_diff_title_match_isbn[100][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodread + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 4 of 2655\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['4390', 'Los funerales de la Mamá Grande', 'Gabriel García Márquez', '3.78', '0307350320', '9780307350329', 'spa', '160', '4694', '133', '2/7/2006', 'Plaza y Janes', 'goodread_id_1267']\n",
      "['bestbook_31_id_28451', '0307350320', 'Los funerales de la MamÃ¡ Grande', [<DOM Element: authors at 0x7fe9d3ac8340>], 'Plaza y Janes', '160', '1962-01-01']\n",
      "Gabriel GarcÃ­a MÃ¡rquez\n",
      "\n",
      "2. Example\n",
      "['4515', 'Las luces de septiembre (Niebla  #3)', 'Carlos Ruiz Zafón', '3.77', '8423671267', '9788423671267', 'spa', '279', '5119', '217', '10/1/2005', 'Edebé', 'goodread_id_1292']\n",
      "['bestbook_31_id_28502', '8423671267', 'Las luces de septiembre', [<DOM Element: authors at 0x7fe9d3b56508>], 'EdebÃ©', '279', '1995-01-01']\n",
      "Carlos Ruiz ZafÃ³n\n",
      "\n",
      "3. Example\n",
      "['16543', 'Dayworld (Dayworld #1)', 'Philip José Farmer', '3.64', '0441140017', '9780441140015', 'eng', '258', '1315', '68', '3/1/1986', 'Ace Books', 'goodread_id_4596']\n",
      "['bestbook_31_id_39256', '0441140017', 'Dayworld', [<DOM Element: authors at 0x7fe9bac95d58>], 'Ace Books', '258', '1985-01-01']\n",
      "Philip JosÃ© Farmer\n"
     ]
    }
   ],
   "source": [
    "goodread_bestbook_diff_title_match_isbn = []\n",
    "same = False\n",
    "for match in matching_pairs_goodread_bestbook:\n",
    "    first_index = int(match[0].split(\"_\")[-1])\n",
    "    second_index = int(match[1].split(\"_\")[-1])\n",
    "\n",
    "    if book_goodread[first_index][1] != bestbook[second_index][2]:\n",
    "        for name in [i.getElementsByTagName(\"name\")[0].firstChild.data for i in bestbook[second_index][3][0].getElementsByTagName(\"author\")]:\n",
    "            for name_2 in book_goodread[first_index][2].split(\"/\"):\n",
    "                if levenshtein_distance(name.replace(\"  \", \" \").lower(), name_2.replace(\"  \", \" \").lower()) < 2:\n",
    "                    same = True\n",
    "        if not same:\n",
    "            goodread_bestbook_diff_title_match_isbn.append(match)\n",
    "\n",
    "        same = False \n",
    "    \n",
    "print(\"\\nTotal: {} of {}\\n\\n\".format(len(goodread_bestbook_diff_title_match_isbn), len(matching_pairs_goodread_bestbook)))\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[int(goodread_bestbook_diff_title_match_isbn[0][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(goodread_bestbook_diff_title_match_isbn[0][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(goodread_bestbook_diff_title_match_isbn[0][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[int(goodread_bestbook_diff_title_match_isbn[1][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(goodread_bestbook_diff_title_match_isbn[1][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(goodread_bestbook_diff_title_match_isbn[1][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[int(goodread_bestbook_diff_title_match_isbn[2][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(goodread_bestbook_diff_title_match_isbn[2][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(goodread_bestbook_diff_title_match_isbn[2][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 1022 of 2655\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['2', 'Harry Potter and the Order of the Phoenix (Harry Potter  #5)', 'J.K. Rowling/Mary GrandPré', '4.49', '0439358078', '9780439358071', 'eng', '870', '2153167', '29221', '9/1/2004', 'Scholastic Inc.', 'goodread_id_1']\n",
      "['bestbook_31_id_41515', '0439358078', 'Harry Potter and the Order of the Phoenix', [<DOM Element: authors at 0x7fe9bc5a6930>], 'Scholastic Inc.', '870', '2003-06-21']\n",
      "J.K. Rowling\n",
      "Mary GrandPrÃ©\n",
      "\n",
      "2. Example\n",
      "['8', 'Harry Potter Boxed Set  Books 1-5 (Harry Potter  #1-5)', 'J.K. Rowling/Mary GrandPré', '4.78', '0439682584', '9780439682589', 'eng', '2690', '41428', '164', '9/13/2004', 'Scholastic', 'goodread_id_4']\n",
      "['bestbook_31_id_50144', '0439682584', 'Harry Potter Boxed Set, Books 1-5 (Harry Potter, #1-5)', [<DOM Element: authors at 0x7fe9c2a4f470>], 'Scholastic', '2690', '2003-10-01']\n",
      "J.K. Rowling\n",
      "Mary GrandPrÃ©\n",
      "\n",
      "3. Example\n",
      "['10', 'Harry Potter Collection (Harry Potter  #1-6)', 'J.K. Rowling', '4.73', '0439827604', '9780439827607', 'eng', '3342', '28242', '808', '9/12/2005', 'Scholastic', 'goodread_id_6']\n",
      "['bestbook_31_id_44052', '0439827604', 'Harry Potter Collection', [<DOM Element: authors at 0x7fe9be3233d8>], 'Scholastic', '3342', '2005-01-01']\n",
      "J.K. Rowling\n"
     ]
    }
   ],
   "source": [
    "goodread_bestbook_diff_title_match_isbn_2 = []\n",
    "same = False\n",
    "for match in matching_pairs_goodread_bestbook:\n",
    "    first_index = int(match[0].split(\"_\")[-1])\n",
    "    second_index = int(match[1].split(\"_\")[-1])\n",
    "\n",
    "    if book_goodread[first_index][1] != bestbook[second_index][2]:\n",
    "        goodread_bestbook_diff_title_match_isbn_2.append(match)\n",
    "\n",
    "\n",
    "print(\"\\nTotal: {} of {}\\n\\n\".format(len(goodread_bestbook_diff_title_match_isbn_2), len(matching_pairs_goodread_bestbook)))\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[int(goodread_bestbook_diff_title_match_isbn_2[0][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(goodread_bestbook_diff_title_match_isbn_2[0][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(goodread_bestbook_diff_title_match_isbn_2[0][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[int(goodread_bestbook_diff_title_match_isbn_2[1][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(goodread_bestbook_diff_title_match_isbn_2[1][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(goodread_bestbook_diff_title_match_isbn_2[1][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[int(goodread_bestbook_diff_title_match_isbn_2[2][0].split(\"_\")[-1])])\n",
    "print(bestbook[int(goodread_bestbook_diff_title_match_isbn_2[2][1].split(\"_\")[-1])])\n",
    "for i in bestbook[int(goodread_bestbook_diff_title_match_isbn_2[2][1].split(\"_\")[-1])][3][0].getElementsByTagName(\"author\"):\n",
    "    print(i.getElementsByTagName(\"name\")[0].firstChild.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodread + Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 180 of 3651\n",
      "\n",
      "\n",
      "1. Example:\n",
      "['180', 'Wrinkles in Time', 'George Smoot/Keay Davidson', '4.01', '0380720442', '9780380720446', 'eng', '360', '1035', '23', '10/1/1994', 'Harper Perennial', 'goodread_id_106']\n",
      "['0380720442', 'Wrinkles in Time  Co', 'G Smoot', '1994', 'Perennial Currents', 'http://images.amazon.com/images/P/0380720442.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/0380720442.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/0380720442.01.LZZZZZZZ.jpg', 'book_crossing_id_218180']\n",
      "\n",
      "2. Example\n",
      "['762', 'Crónica de una muerte anunciada', 'Gabriel García Márquez', '3.97', '1400034957', '9781400034956', 'spa', '118', '7888', '411', '10/14/2003', 'Vintage Espanol', 'goodread_id_255']\n",
      "['1400034957', 'Cronica de una muerte anunciada (Vintage Espanol)', 'GABRIEL GARCIA MARQUEZ', '2003', 'Vintage', 'http://images.amazon.com/images/P/1400034957.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/1400034957.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/1400034957.01.LZZZZZZZ.jpg', 'book_crossing_id_25655']\n",
      "\n",
      "3. Example\n",
      "['1423', 'The Compleat Works of Wllm Shkspr (abridged)', 'Reduced Shakespeare Company/Adam Long/Daniel Singer/Jess Winfield', '4.44', '1557831572', '9781557831576', 'eng', '137', '8159', '118', '2/1/1994', 'Applause Books', 'goodread_id_423']\n",
      "['1557831572', 'The Complete Works of William Shakespeare : Reduced Shakespeare Company Presents', 'Jess Borgeson', '1993', 'Applause Theatre &amp; Cinema Book Publishers', 'http://images.amazon.com/images/P/1557831572.01.THUMBZZZ.jpg', 'http://images.amazon.com/images/P/1557831572.01.MZZZZZZZ.jpg', 'http://images.amazon.com/images/P/1557831572.01.LZZZZZZZ.jpg', 'book_crossing_id_42130']\n"
     ]
    }
   ],
   "source": [
    "goodread_crossing_diff_title_match_isbn = []\n",
    "same = False\n",
    "for match in matching_pairs_goodread_crossing:\n",
    "    first_index = int(match[0].split(\"_\")[-1])\n",
    "    second_index = int(match[1].split(\"_\")[-1])\n",
    "    same = False \n",
    "    if book_goodread[first_index][1] != book_crossing[second_index][1]:\n",
    "        for name in book_goodread[first_index][2].split(\"/\"):\n",
    "            if levenshtein_distance(\"\".join(name.lower().split()), \"\".join(book_crossing[second_index][2].lower().split())) < 2:\n",
    "                #print(\"\".join(name.lower().split()))\n",
    "                #print(\"\".join(book_crossing[second_index][2].lower().split()))\n",
    "                same = True\n",
    "        if not same:\n",
    "       \n",
    "            goodread_crossing_diff_title_match_isbn.append(match)\n",
    "    \n",
    "        \n",
    "print(\"\\nTotal: {} of {}\\n\\n\".format(len(goodread_crossing_diff_title_match_isbn), len(matching_pairs_goodread_crossing)))\n",
    "# Examples:\n",
    "print(\"1. Example:\")\n",
    "print(book_goodread[int(goodread_crossing_diff_title_match_isbn[0][0].split(\"_\")[-1])])\n",
    "print(book_crossing[int(goodread_crossing_diff_title_match_isbn[0][1].split(\"_\")[-1])])\n",
    "\n",
    "    \n",
    "print(\"\\n2. Example\")\n",
    "print(book_goodread[int(goodread_crossing_diff_title_match_isbn[1][0].split(\"_\")[-1])])\n",
    "print(book_crossing[int(goodread_crossing_diff_title_match_isbn[1][1].split(\"_\")[-1])])\n",
    "\n",
    "    \n",
    "print(\"\\n3. Example\")\n",
    "print(book_goodread[int(goodread_crossing_diff_title_match_isbn[3][0].split(\"_\")[-1])])\n",
    "print(book_crossing[int(goodread_crossing_diff_title_match_isbn[3][1].split(\"_\")[-1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossing_bestbook_cornercase_1 = []\n",
    "for i in crossing_bestbook_matching_title_diff_authors_diff:\n",
    "    crossing_bestbook_cornercase_1.append([i[0], i[1], \"False\"])\n",
    "    \n",
    "crossing_bestbook_cornercase_2 = []\n",
    "for i in crossing_bestbook_matching_title_matching_authors_diff:\n",
    "    crossing_bestbook_cornercase_2.append([i[0], i[1], \"False\"])\n",
    "    \n",
    "crossing_bestbook_cornercase_3 = crossing_bestbook_diff_title_match_isbn\n",
    "\n",
    "\n",
    "goodread_bestbook_cornercase_1 = []\n",
    "for i in goodread_bestbook_matching_title_diff_authors_diff:\n",
    "    goodread_bestbook_cornercase_1.append([i[0], i[1], \"False\"])\n",
    "    \n",
    "goodread_bestbook_cornercase_2 = []\n",
    "for i in goodread_bestbook_matching_title_matching_authors_diff:\n",
    "    goodread_bestbook_cornercase_2.append([i[0], i[1], \"False\"])\n",
    "    \n",
    "goodread_bestbook_cornercase_3 = goodread_bestbook_diff_title_match_isbn_2\n",
    "\n",
    "\n",
    "\n",
    "goodread_crossing_cornercase_1 = []\n",
    "for i in goodread_crossing_matching_title_diff_authors_diff:\n",
    "    goodread_crossing_cornercase_1.append([i[0], i[1], \"False\"])\n",
    "    \n",
    "goodread_crossing_cornercase_2 = []\n",
    "for i in goodread_crossing_matching_title_matching_authors_diff:\n",
    "    goodread_crossing_cornercase_2.append([i[0], i[1], \"False\"])\n",
    "    \n",
    "goodread_crossing_cornercase_3 = goodread_crossing_diff_title_match_isbn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating of Gold standard Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Set samples of gold standard set\n",
    "n = 500\n",
    "\n",
    "\n",
    "matching_pairs_number = int(n * 0.2)\n",
    "matching_pairs_number_corner_1 = int(n * 0.1)\n",
    "matching_pairs_number_corner_2 = int(n * 0.1)\n",
    "matching_pairs_number_corner_3 = int(n * 0.1)\n",
    "non_matching_pairs_number = int(n * 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching record pairs, randomly chosen, 20%\n",
    "\n",
    "\n",
    "Corner Cases, 30%:\n",
    "- (1) Matching Titles, matching authors, but different ISBN, 10%\n",
    "- (2) Matching Titles, different authors, but different ISBN, 10%\n",
    "- (3) Different Title, different authors but same ISBN, 10%\n",
    "\n",
    "\n",
    "Non-matching record pairs, 50%\n",
    "\n",
    "\n",
    "Randomly chosen without replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_non_matching(data1, data2, matching_pairs_crop):\n",
    "    random_sample1 = random.choice(data1)\n",
    "    random_sample2 = random.choice(data2)\n",
    "\n",
    "    if [random_sample1, random_sample2] not in matching_pairs_crop:\n",
    "        return [random_sample1, random_sample2, \"False\"]\n",
    "    else: \n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Gold Standard Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossing_bestbook_gs = []\n",
    "goodread_crossing_gs = []\n",
    "goodread_bestbook_gs = []\n",
    "\n",
    "with open('crossing_bestbook_final_GS.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        crossing_bestbook_gs.append(row)\n",
    "        \n",
    "\n",
    "        \n",
    "goodread_bestbook_gs = []\n",
    "with open('goodread_bestbook_final_GS.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        goodread_bestbook_gs.append(row)\n",
    "        \n",
    "goodread_crossing_gs = []\n",
    "with open('goodread_crossing_final_GS.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        goodread_crossing_gs.append(row)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "crossing_bestbook_train = []\n",
    "with open('crossing_bestbook_training_set.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        crossing_bestbook_train.append(row)\n",
    "        \n",
    "goodread_bestbook_train = []\n",
    "with open('goodread_bestbook_training_set.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        goodread_bestbook_train.append(row)\n",
    "        \n",
    "goodread_crossing_train = []\n",
    "with open('goodread_crossing_training_set.csv', newline='', encoding='utf-8', errors='ignore') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for index, row in enumerate(spamreader):\n",
    "        goodread_crossing_train.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Set samples of gold standard set\n",
    "n = 500\n",
    "\n",
    "\n",
    "matching_pairs_number = int(n * 0.2)\n",
    "matching_pairs_number_corner_1 = int(n * 0.1)\n",
    "matching_pairs_number_corner_2 = int(n * 0.1)\n",
    "matching_pairs_number_corner_3 = int(n * 0.1)\n",
    "non_matching_pairs_number = int(n * 0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sample_non_matching(data1, data2, matching_pairs_crop):\n",
    "    random_sample1 = random.choice(data1)\n",
    "    random_sample2 = random.choice(data2)\n",
    "\n",
    "    if [random_sample1, random_sample2] not in matching_pairs_crop:\n",
    "        return [random_sample1, random_sample2, \"False\"]\n",
    "    else: \n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossing + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# PARAMETER WHICH SAMPLES SHOULD NOT BE INCLUDED\n",
    "crossing_bestbook_exclude = crossing_bestbook_train + crossing_bestbook_gs\n",
    "\n",
    "\n",
    "# Corner Cases, 30%:\n",
    "# (1) Matching Titles, matching authors, but different ISBN, 10%\n",
    "crossing_bestbook_cornercase_1_chosen = []\n",
    "while len(crossing_bestbook_cornercase_1_chosen) < matching_pairs_number_corner_1:\n",
    "    a = random.sample(crossing_bestbook_cornercase_1, k=1)[0]\n",
    "    if a not in crossing_bestbook_exclude and a not in crossing_bestbook_cornercase_1_chosen:\n",
    "        crossing_bestbook_cornercase_1_chosen.append(a)\n",
    "\n",
    "# (2) Matching Titles, different authors, but different ISBN, 10%\n",
    "crossing_bestbook_cornercase_2_chosen = []\n",
    "while len(crossing_bestbook_cornercase_2_chosen) < matching_pairs_number_corner_2:\n",
    "    a = random.sample(crossing_bestbook_cornercase_2, k=1)[0]\n",
    "    if a not in crossing_bestbook_exclude and a not in crossing_bestbook_cornercase_2_chosen:\n",
    "        crossing_bestbook_cornercase_2_chosen.append(a)\n",
    "      \n",
    "    \n",
    "\n",
    "        \n",
    "# (3) Different Title, different authors but same ISBN, 10%\n",
    "crossing_bestbook_cornercase_3_chosen = []\n",
    "while len(crossing_bestbook_cornercase_3_chosen) < matching_pairs_number_corner_3:\n",
    "    a = random.sample(crossing_bestbook_cornercase_3, k=1)[0]\n",
    "    \n",
    "    if a not in crossing_bestbook_exclude and a not in crossing_bestbook_cornercase_3_chosen:\n",
    "        print(len(crossing_bestbook_cornercase_3_chosen))\n",
    "        crossing_bestbook_cornercase_3_chosen.append(a)\n",
    "        \n",
    "        \n",
    "crossing_bestbook_cornercase = crossing_bestbook_cornercase_1_chosen \\\n",
    "+ crossing_bestbook_cornercase_2_chosen \\\n",
    "+ crossing_bestbook_cornercase_3_chosen\n",
    "\n",
    "# Matching record pairs, randomly chosen, 20%\n",
    "crossing_bestbook_chosen_matches = []\n",
    "while matching_pairs_number > len(crossing_bestbook_chosen_matches):\n",
    "    b = random.choice(matching_pairs_crossing_bestbook)\n",
    "    if b not in crossing_bestbook_cornercase and b not in crossing_bestbook_exclude and b not in crossing_bestbook_chosen_matches:\n",
    "        crossing_bestbook_chosen_matches.append(b)\n",
    "\n",
    "\n",
    "        \n",
    "# Non-matching record pairs, 50%\n",
    "matching_pairs_crop = []\n",
    "for i in matching_pairs_crossing_bestbook:\n",
    "    matching_pairs_crop.append(i[:2])\n",
    "crossing_bestbook_non_matching_chosen = []\n",
    "while non_matching_pairs_number > len(crossing_bestbook_non_matching_chosen):\n",
    "    a = sample_non_matching([i[-1] for i in book_crossing], [i[0] for i in bestbook], matching_pairs_crop)\n",
    "    if a != [] and a not in crossing_bestbook_non_matching_chosen and a not in crossing_bestbook_cornercase \\\n",
    "    and a not in crossing_bestbook_exclude:\n",
    "        crossing_bestbook_non_matching_chosen.append(a)\n",
    "\n",
    "\n",
    "\n",
    "# Writing to File\n",
    "\n",
    "### Crossing + Bestbook\n",
    "\n",
    "crossing_bestbook_GS = crossing_bestbook_chosen_matches \\\n",
    "+ crossing_bestbook_cornercase_1_chosen \\\n",
    "+ crossing_bestbook_cornercase_2_chosen \\\n",
    "+ crossing_bestbook_cornercase_3_chosen + crossing_bestbook_non_matching_chosen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodread + Bestbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARAMETER WHICH SAMPLES SHOULD NOT BE INCLUDED\n",
    "goodread_bestbook_exclude = goodread_bestbook_train + goodread_bestbook_gs\n",
    "\n",
    "\n",
    "# Corner Cases, 30%:\n",
    "# (1) Matching Titles, matching authors, but different ISBN, 10%\n",
    "goodread_bestbook_cornercase_1_chosen = []\n",
    "while len(goodread_bestbook_cornercase_1_chosen) < matching_pairs_number_corner_1:\n",
    "    a = random.sample(goodread_bestbook_cornercase_1, k=1)[0]\n",
    "    if a not in goodread_bestbook_exclude and a not in goodread_bestbook_cornercase_1_chosen:\n",
    "        goodread_bestbook_cornercase_1_chosen.append(a)\n",
    "        \n",
    "\n",
    "\n",
    "# (2) Matching Titles, different authors, but different ISBN, 10%\n",
    "goodread_bestbook_cornercase_2_chosen = []\n",
    "while len(goodread_bestbook_cornercase_2_chosen) < matching_pairs_number_corner_2:\n",
    "    a = random.sample(goodread_bestbook_cornercase_2, k=1)[0]\n",
    "    if a not in goodread_bestbook_exclude and a not in goodread_bestbook_cornercase_2_chosen:\n",
    "        goodread_bestbook_cornercase_2_chosen.append(a)\n",
    "        \n",
    "\n",
    "        \n",
    "# (3) Different Title, different authors but same ISBN, 10%\n",
    "goodread_bestbook_cornercase_3_chosen = []\n",
    "while len(goodread_bestbook_cornercase_3_chosen) < matching_pairs_number_corner_3:\n",
    "    a = random.sample(goodread_bestbook_cornercase_3, k=1)[0]\n",
    "    if a not in goodread_bestbook_exclude and a not in goodread_bestbook_cornercase_3_chosen:\n",
    "        goodread_bestbook_cornercase_3_chosen.append(a)\n",
    "\n",
    "\n",
    "goodread_bestbook_cornercase = goodread_bestbook_cornercase_1_chosen \\\n",
    "+ goodread_bestbook_cornercase_2_chosen \\\n",
    "+ goodread_bestbook_cornercase_3_chosen\n",
    "\n",
    "\n",
    "\n",
    "# Matching record pairs, randomly chosen, 20%\n",
    "goodread_bestbook_chosen_matches = []\n",
    "while matching_pairs_number > len(goodread_bestbook_chosen_matches):\n",
    "    b = random.choice(matching_pairs_goodread_bestbook)\n",
    "    if b not in goodread_bestbook_cornercase and b not in goodread_bestbook_exclude \\\n",
    "    and b not in goodread_bestbook_chosen_matches:\n",
    "        goodread_bestbook_chosen_matches.append(b)\n",
    "\n",
    "# Non-matching record pairs, 50%\n",
    "matching_pairs_crop = []\n",
    "for i in matching_pairs_goodread_bestbook:\n",
    "    matching_pairs_crop.append(i[:2])\n",
    "goodread_bestbook_non_matching_chosen = []\n",
    "while non_matching_pairs_number > len(goodread_bestbook_non_matching_chosen):\n",
    "    a = sample_non_matching([i[-1] for i in book_goodread], [i[0] for i in bestbook], matching_pairs_crop)\n",
    "    if a != [] and a not in goodread_bestbook_non_matching_chosen and a not in goodread_bestbook_cornercase\\\n",
    "    and a not in goodread_bestbook_exclude:\n",
    "        goodread_bestbook_non_matching_chosen.append(a)\n",
    "        \n",
    "        \n",
    "### Goodread + Bestbook\n",
    "\n",
    "goodread_bestbook_GS = goodread_bestbook_chosen_matches \\\n",
    "+ goodread_bestbook_cornercase_1_chosen \\\n",
    "+ goodread_bestbook_cornercase_2_chosen \\\n",
    "+ goodread_bestbook_cornercase_3_chosen + goodread_bestbook_non_matching_chosen\n",
    "\n",
    "\n",
    "len(set([tuple(i) for i in goodread_bestbook_GS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodread + Book Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARAMETER WHICH SAMPLES SHOULD NOT BE INCLUDED\n",
    "\n",
    "goodread_crossing_exclude = goodread_crossing_train + goodread_crossing_gs\n",
    "\n",
    "\n",
    "# Corner Cases, 30%:\n",
    "# (1) Matching Titles, matching authors, but different ISBN, 10%\n",
    "goodread_crossing_cornercase_1_chosen = []\n",
    "while len(goodread_crossing_cornercase_1_chosen) < matching_pairs_number_corner_1:\n",
    "    a = random.sample(goodread_crossing_cornercase_1, k=1)[0]\n",
    "    if a not in goodread_crossing_exclude and a not in goodread_crossing_cornercase_1_chosen:\n",
    "        goodread_crossing_cornercase_1_chosen.append(a)\n",
    "        \n",
    "\n",
    "\n",
    "# (2) Matching Titles, different authors, but different ISBN, 10%\n",
    "goodread_crossing_cornercase_2_chosen = []\n",
    "while len(goodread_crossing_cornercase_2_chosen) < matching_pairs_number_corner_2:\n",
    "    a = random.sample(goodread_crossing_cornercase_2, k=1)[0]\n",
    "    if a not in goodread_crossing_exclude and a not in goodread_crossing_cornercase_2_chosen:\n",
    "        goodread_crossing_cornercase_2_chosen.append(a)\n",
    "        \n",
    "\n",
    "        \n",
    "# (3) Different Title, different authors but same ISBN, 10%\n",
    "goodread_crossing_cornercase_3_chosen = []\n",
    "while len(goodread_crossing_cornercase_3_chosen) < matching_pairs_number_corner_3:\n",
    "    a = random.sample(goodread_crossing_cornercase_3, k=1)[0]\n",
    "    if a not in goodread_crossing_exclude and a not in goodread_crossing_cornercase_3_chosen:\n",
    "        goodread_crossing_cornercase_3_chosen.append(a)\n",
    "\n",
    "\n",
    "\n",
    "goodread_crossing_cornercase = goodread_crossing_cornercase_1_chosen \\\n",
    "+ goodread_crossing_cornercase_2_chosen \\\n",
    "+ goodread_crossing_cornercase_3_chosen\n",
    "\n",
    "# Matching record pairs, randomly chosen, 20%\n",
    "goodread_crossing_chosen_matches = []\n",
    "while matching_pairs_number > len(goodread_crossing_chosen_matches):\n",
    "    b = random.choice(matching_pairs_goodread_crossing)\n",
    "    if b not in goodread_crossing_cornercase and b not in goodread_crossing_chosen_matches \\\n",
    "    and b not in goodread_crossing_exclude:\n",
    "        goodread_crossing_chosen_matches.append(b)\n",
    "\n",
    "# Non-matching record pairs, 50%\n",
    "matching_pairs_crop = []\n",
    "for i in matching_pairs_goodread_crossing:\n",
    "    matching_pairs_crop.append(i[:2])\n",
    "goodread_crossing_non_matching_chosen = []\n",
    "while non_matching_pairs_number > len(goodread_crossing_non_matching_chosen):\n",
    "    a = sample_non_matching([i[-1] for i in book_goodread], [i[-1] for i in book_crossing], matching_pairs_crop)\n",
    "    if a != [] and a not in goodread_crossing_non_matching_chosen and a not in goodread_crossing_cornercase\\\n",
    "    and a not in goodread_crossing_exclude:\n",
    "        goodread_crossing_non_matching_chosen.append(a)\n",
    "\n",
    "        \n",
    "### Goodread + Crossing\n",
    "\n",
    "goodread_crossing_GS = goodread_crossing_chosen_matches \\\n",
    "+ goodread_crossing_cornercase_1_chosen \\\n",
    "+ goodread_crossing_cornercase_2_chosen \\\n",
    "+ goodread_crossing_cornercase_3_chosen + goodread_crossing_non_matching_chosen\n",
    "\n",
    "\n",
    "len(set([tuple(i) for i in goodread_crossing_GS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crossing_bestbook_validation_gs.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in crossing_bestbook_GS:\n",
    "        filewriter.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('goodread_bestbook_validation_gs.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in goodread_bestbook_GS:\n",
    "        filewriter.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('goodread_crossing_validation_gs.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in goodread_crossing_GS:\n",
    "        filewriter.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection(goodread_crossing_GS, goodread_crossing_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
